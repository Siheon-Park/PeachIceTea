{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import pennylane.numpy as np\n",
    "import torch\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "from torch.optim import Adam, Adagrad\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from QCNN_circuit_only import QCNN\n",
    "from ansatz import ConvCirc1, PoolingCirc\n",
    "\n",
    "qcnn = QCNN(n_qubits=8, conv_ansatz=ConvCirc1(), pooling_ansatz=PoolingCirc(), stride=1)\n",
    "\n",
    "dev = qml.device('default.qubit', wires=2)\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def circuit(params, data):\n",
    "    qcnn.construct_circuit(params, data)\n",
    "    return qml.expval(qml.PauliZ(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, concat\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_name):\n",
    "        self.data = read_csv(file_name)\n",
    "\n",
    "    def filter(self, labels):\n",
    "        data_list  = []\n",
    "        for label in labels:\n",
    "            data_list.append(self.data[self.data[\"label\"]==label])\n",
    "        self.data = concat(data_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.data.iloc[index]['label']\n",
    "        image = self.data.iloc[index][1:]\n",
    "        return torch.tensor(image), torch.tensor(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 5000 instances\n",
      "test set has 7665 instances\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: use postprocessed data instead\n",
    "# ====================================\n",
    "#transform = transforms.Compose(\n",
    "#    [transforms.ToTensor(),\n",
    "#    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & test, download if necessary\n",
    "#training_set = torchvision.datasets.MNIST('./data', train=True, transform=transform, download=True)\n",
    "#training_set, validation_set = random_split(training_set, [50000, 10000])\n",
    "#test_set = torchvision.datasets.MNIST('./data', train=False, transform=transform, download=True)\n",
    "training_set = MyDataset('train_pca_256.csv') \n",
    "training_set.filter([0, 1])#torchvision.datasets.MNIST('./data', train=True, transform=transform, download=True)\n",
    "training_set, validation_set = random_split(training_set, [5000, len(training_set)-5000])\n",
    "test_set = MyDataset('test_pca_256.csv') \n",
    "test_set.filter([0, 1])\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for test\n",
    "training_loader = DataLoader(training_set, batch_size=25, shuffle=True, num_workers=2)\n",
    "validation_loader = DataLoader(validation_set, batch_size=25, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=25, shuffle=False, num_workers=2)\n",
    "\n",
    "# ====================================\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('test set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = MSELoss() # TODO: choose loss function\n",
    "params = torch.rand(qcnn.Calculate_Param_Num(), requires_grad=True) # TODO: choose params length\n",
    "\n",
    "optimizer = Adam([params], lr=0.01) # TODO: choose optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'MyDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/shaun/PeachIceTea/train.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shaun/PeachIceTea/train.ipynb#ch0000006?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shaun/PeachIceTea/train.ipynb#ch0000006?line=9'>10</a>\u001b[0m     avg_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/shaun/PeachIceTea/train.ipynb#ch0000006?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39;49m(training_loader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(training_loader), desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shaun/PeachIceTea/train.ipynb#ch0000006?line=11'>12</a>\u001b[0m         inputs, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shaun/PeachIceTea/train.ipynb#ch0000006?line=12'>13</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py:368\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=365'>366</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=366'>367</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=367'>368</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py:314\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=311'>312</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=312'>313</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=313'>314</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py:927\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=919'>920</a>\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=920'>921</a>\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=921'>922</a>\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=922'>923</a>\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=923'>924</a>\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=924'>925</a>\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=925'>926</a>\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=926'>927</a>\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=927'>928</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=928'>929</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/process.py?line=117'>118</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/process.py?line=118'>119</a>\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/process.py?line=119'>120</a>\u001b[0m _cleanup()\n\u001b[0;32m--> <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/process.py?line=120'>121</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/process.py?line=121'>122</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/process.py?line=122'>123</a>\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/process.py?line=123'>124</a>\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/context.py?line=221'>222</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/context.py?line=222'>223</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/context.py?line=223'>224</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/context.py?line=280'>281</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/context.py?line=281'>282</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/context.py?line=282'>283</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/context.py?line=283'>284</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=30'>31</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=31'>32</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/popen_fork.py?line=16'>17</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/popen_fork.py?line=17'>18</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/popen_fork.py?line=18'>19</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=59'>60</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=60'>61</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=61'>62</a>\u001b[0m         f\u001b[39m.\u001b[39;49mwrite(fp\u001b[39m.\u001b[39;49mgetbuffer())\n\u001b[1;32m     <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=62'>63</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/shaun/anaconda3/envs/qiskit/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=63'>64</a>\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def estimated_label(params, data):\n",
    "    return circuit(params, data) # TODO: customize your extimated label\n",
    "\n",
    "writer = SummaryWriter(log_dir='./runs')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    avg_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(training_loader), total=len(training_loader), desc=f\"{epoch}\"):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        loss = torch.tensor(0, dtype=torch.float64)\n",
    "        for input, label in zip(inputs, labels):\n",
    "            output = estimated_label(params, inputs.to(torch.float64))\n",
    "            loss+=loss_fn(output, label.to(torch.float64))/len(labels)\n",
    "        loss.backward()       \n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()\n",
    "        \n",
    "    avg_loss = avg_loss/len(training_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        avg_vloss = 0.0\n",
    "        for i, vdata in enumerate(test_loader):\n",
    "            vloss = torch.tensor(0, dtype=torch.float64)\n",
    "            vinputs, vlabels = vdata\n",
    "            for vinput, vlabel in zip(vinputs, vlabels):\n",
    "                voutput = estimated_label(params, vinput.to(torch.float64))\n",
    "                vloss += loss_fn(voutput, vlabel.to(torch.float64))/len(vlabels)\n",
    "            avg_vloss += vloss\n",
    "        avg_vloss = avg_vloss/len(test_loader)\n",
    "    # print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and test\n",
    "    writer.add_scalars('Training vs. test Loss',\n",
    "                    { 'Training' : avg_loss, 'test' : avg_vloss },\n",
    "                    epoch)\n",
    "    writer.flush()\n",
    "        # print('{}: {}'.format(i, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b62b6089cd174fcd23de5a2ba1f03f98164a35935839c99f5cfe650d529eeaec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('qiskit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
